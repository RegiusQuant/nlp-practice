{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text Sample: ﻿project gutenberg’s real soldiers of fortune, by \n",
      "Raw Text Length: 276830\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('/media/bnu/data/nlp-practice/text-generation/Winston_Churchil.txt')\n",
    "with open(data_path) as f:\n",
    "    raw_text = f.read()\n",
    "raw_text = raw_text.lower()\n",
    "print('Raw Text Sample:', raw_text[:50])\n",
    "print('Raw Text Length:', len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Char: 61\n",
      "Char to Index:\n",
      "{'\\n': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '(': 6, ')': 7, '*': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, ';': 24, '?': 25, '@': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55, '‘': 56, '’': 57, '“': 58, '”': 59, '\\ufeff': 60}\n"
     ]
    }
   ],
   "source": [
    "# 对数据进行编码\n",
    "char_list = sorted(list(set(raw_text)))\n",
    "char_to_idx = {c: i for i, c in enumerate(char_list)}\n",
    "idx_to_char = {i: c for i, c in enumerate(char_list)}\n",
    "\n",
    "print('Number of Char:', len(char_list))\n",
    "print('Char to Index:')\n",
    "print(char_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Sample:\n",
      "[50, 49, 34, 43, 31, 34, 47, 36, 57, 48, 1, 47, 34, 30, 41, 1, 48, 44, 41, 33, 38, 34, 47, 48, 1, 44, 35, 1, 35, 44, 47, 49, 50, 43, 34, 9, 1, 31, 54, 1, 47, 38, 32, 37, 30, 47, 33, 1, 37, 30, 47, 33, 38, 43, 36, 1, 33, 30, 51, 38, 48, 0, 0, 49, 37, 38, 48, 1, 34, 31, 44, 44, 40, 1, 38, 48, 1, 35, 44, 47, 1, 49, 37, 34, 1, 50, 48, 34, 1, 44, 35, 1, 30, 43, 54, 44, 43, 34, 1, 30]\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 100  # 训练集中的序列长度\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(len(raw_text) - sequence_length):\n",
    "    x_temp = [char_to_idx[c] for c in raw_text[i: i+sequence_length]]\n",
    "    y_temp = char_to_idx[raw_text[i+sequence_length]]\n",
    "    x_train.append(x_temp)\n",
    "    y_train.append(y_temp)\n",
    "\n",
    "print('Train Data Sample:')\n",
    "print(x_train[10])\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape: (276730, 100, 1)\n",
      "Y Train Shape: (276730, 60)\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(x_train)\n",
    "num_vocabs = len(char_list)\n",
    "\n",
    "# 将x_train的形状修改为LSTM所需的\n",
    "x_train = np.reshape(x_train, (num_samples, sequence_length, 1))\n",
    "# 对x_train的数据进行简单归一化\n",
    "x_train = x_train / float(num_vocabs)\n",
    "# 对y进行one-hot编码\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "print('X Train Shape:', x_train.shape)\n",
    "print('Y Train Shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 249057 samples, validate on 27673 samples\n",
      "Epoch 1/50\n",
      "249057/249057 [==============================] - 13s 53us/step - loss: 3.1572 - val_loss: 3.0708\n",
      "Epoch 2/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 3.0227 - val_loss: 3.0669\n",
      "Epoch 3/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 3.0069 - val_loss: 3.0573\n",
      "Epoch 4/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.9798 - val_loss: 3.0343\n",
      "Epoch 5/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.9332 - val_loss: 3.0076\n",
      "Epoch 6/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.8930 - val_loss: 2.9941\n",
      "Epoch 7/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.8754 - val_loss: 2.9916\n",
      "Epoch 8/50\n",
      "249057/249057 [==============================] - 12s 50us/step - loss: 2.8622 - val_loss: 2.9758\n",
      "Epoch 9/50\n",
      "249057/249057 [==============================] - 12s 50us/step - loss: 2.8512 - val_loss: 2.9749\n",
      "Epoch 10/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.8401 - val_loss: 2.9673\n",
      "Epoch 11/50\n",
      "249057/249057 [==============================] - 12s 50us/step - loss: 2.8289 - val_loss: 2.9612\n",
      "Epoch 12/50\n",
      "249057/249057 [==============================] - 12s 50us/step - loss: 2.8187 - val_loss: 2.9473\n",
      "Epoch 13/50\n",
      "249057/249057 [==============================] - 12s 50us/step - loss: 2.8079 - val_loss: 2.9462\n",
      "Epoch 14/50\n",
      "249057/249057 [==============================] - 12s 50us/step - loss: 2.8006 - val_loss: 2.9318\n",
      "Epoch 15/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.7907 - val_loss: 2.9248\n",
      "Epoch 16/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.7836 - val_loss: 2.9240\n",
      "Epoch 17/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.7767 - val_loss: 2.9140\n",
      "Epoch 18/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.7694 - val_loss: 2.9117\n",
      "Epoch 19/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7630 - val_loss: 2.9052\n",
      "Epoch 20/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7579 - val_loss: 2.8976\n",
      "Epoch 21/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7519 - val_loss: 2.8951\n",
      "Epoch 22/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7464 - val_loss: 2.8944\n",
      "Epoch 23/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7425 - val_loss: 2.8894\n",
      "Epoch 24/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7366 - val_loss: 2.8863\n",
      "Epoch 25/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7318 - val_loss: 2.8814\n",
      "Epoch 26/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7267 - val_loss: 2.8789\n",
      "Epoch 27/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7210 - val_loss: 2.8762\n",
      "Epoch 28/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7147 - val_loss: 2.8747\n",
      "Epoch 29/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7104 - val_loss: 2.8753\n",
      "Epoch 30/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.7050 - val_loss: 2.8649\n",
      "Epoch 31/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.6987 - val_loss: 2.8684\n",
      "Epoch 32/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6942 - val_loss: 2.8641\n",
      "Epoch 33/50\n",
      "249057/249057 [==============================] - 13s 50us/step - loss: 2.6875 - val_loss: 2.8597\n",
      "Epoch 34/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6817 - val_loss: 2.8552\n",
      "Epoch 35/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6764 - val_loss: 2.8548\n",
      "Epoch 36/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6701 - val_loss: 2.8582\n",
      "Epoch 37/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6673 - val_loss: 2.8464\n",
      "Epoch 38/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6592 - val_loss: 2.8448\n",
      "Epoch 39/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6540 - val_loss: 2.8432\n",
      "Epoch 40/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6466 - val_loss: 2.8405\n",
      "Epoch 41/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6404 - val_loss: 2.8426\n",
      "Epoch 42/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6344 - val_loss: 2.8355\n",
      "Epoch 43/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6288 - val_loss: 2.8324\n",
      "Epoch 44/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6222 - val_loss: 2.8279\n",
      "Epoch 45/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6165 - val_loss: 2.8259\n",
      "Epoch 46/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6098 - val_loss: 2.8322\n",
      "Epoch 47/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.6029 - val_loss: 2.8270\n",
      "Epoch 48/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.5974 - val_loss: 2.8232\n",
      "Epoch 49/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.5914 - val_loss: 2.8295\n",
      "Epoch 50/50\n",
      "249057/249057 [==============================] - 13s 51us/step - loss: 2.5846 - val_loss: 2.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4c3d1e66d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=4096, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(input_array):\n",
    "    \"\"\"根据输入的文本特征预测下一个字符\"\"\"\n",
    "    test_data = np.reshape(input_array, (1, sequence_length, 1))\n",
    "    test_data = test_data / float(num_vocabs)\n",
    "    return model.predict(test_data)\n",
    "\n",
    "def string_to_index(input_string):\n",
    "    \"\"\"将文本中末尾的字符转换为特征\"\"\"\n",
    "    return [char_to_idx[c] for c in input_string[-sequence_length:]]\n",
    "\n",
    "def pred_to_char(pred):\n",
    "    \"\"\"根据预测值获取字符\"\"\"\n",
    "    return idx_to_char[pred.argmax()]\n",
    "\n",
    "def generate_text(init_string, steps=200):\n",
    "    \"\"\"根据初始字符串生成文本\"\"\"\n",
    "    result = init_string.lower()\n",
    "    for i in range(steps):\n",
    "        c = pred_to_char(predict_next(string_to_index(result)))\n",
    "        result += c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his object in coming to new york was to engage officers for that service. he came at an opportune moment of the cornin of the carine tf the cornin of the carine tf the cornin of the carine and the torer of the carine and the torer of the carine and the torer of the carine and the torer of the carine and\n"
     ]
    }
   ],
   "source": [
    "init_string = 'His object in coming to New York was to engage officers for that service. He came at an opportune moment'\n",
    "result = generate_text(init_string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(2020)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何处理文本数据\n",
    "text_field = torchtext.data.Field(lower=True)\n",
    "\n",
    "# 构建语言模型数据集\n",
    "train_data, valid_data, test_data = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "    path=Path('/media/bnu/data/nlp-practice/language-model'),\n",
    "    train='text8.train.txt',\n",
    "    validation='text8.dev.txt',\n",
    "    test='text8.test.txt',\n",
    "    text_field=text_field\n",
    ")\n",
    "\n",
    "# 构建词汇表 \n",
    "text_field.build_vocab(train_data, max_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 50002\n",
      "------------------------------------------------------------\n",
      "Index to Word Sample:\n",
      "['<unk>', '<pad>', 'the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero']\n",
      "------------------------------------------------------------\n",
      "Word to Index Sample:\n",
      "[('<unk>', 0), ('<pad>', 1), ('the', 2), ('of', 3), ('and', 4), ('one', 5), ('in', 6), ('a', 7), ('to', 8), ('zero', 9)]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 实际单词表大小\n",
    "print('Vocab Size:', len(text_field.vocab))\n",
    "print('-' * 60)\n",
    "\n",
    "# Index -> Word\n",
    "print('Index to Word Sample:')\n",
    "print(text_field.vocab.itos[:10])\n",
    "print('-' * 60)\n",
    "\n",
    "# Word -> Index\n",
    "print('Word to Index Sample:')\n",
    "print(list(text_field.vocab.stoi.items())[:10])\n",
    "print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成BPTT迭代器\n",
    "train_iter, valid_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_sizes=(32, 32, 32),\n",
    "    device=device,\n",
    "    bptt_len=50,\n",
    "    repeat=False,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Data:\n",
      "\n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.text]:[torch.cuda.LongTensor of size 50x32 (GPU 0)]\n",
      "\t[.target]:[torch.cuda.LongTensor of size 50x32 (GPU 0)]\n",
      "------------------------------------------------------------\n",
      "Input:\n",
      "combine in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets of supposedly fundamental quarks combine to create most typical forms of matter they had also suggested the possibility\n",
      "Target:\n",
      "in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets of supposedly fundamental quarks combine to create most typical forms of matter they had also suggested the possibility of\n"
     ]
    }
   ],
   "source": [
    "# 查看维度 (seq_len * batch_size)\n",
    "batch_data = next(iter(train_iter))\n",
    "print('Batch Data:')\n",
    "print(batch_data)\n",
    "print('-' * 60)\n",
    "\n",
    "# 查看输入\n",
    "print('Input:')\n",
    "print(' '.join([text_field.vocab.itos[i] for i in batch_data.text[:, 1]]))\n",
    "\n",
    "# 查看目标\n",
    "print('Target:')\n",
    "print(' '.join([text_field.vocab.itos[i] for i in batch_data.target[:, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_type, n_token, n_embed, n_hidden, \n",
    "                 n_layers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.embed = nn.Embedding(n_token, n_embed)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(\n",
    "                n_embed, n_hidden, n_layers, dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(\"rnn_type must in ['LSTM', 'GRU']\")\n",
    "        self.linear = nn.Linear(n_hidden, n_token)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # inputs shape: (seq_len, batch_size)\n",
    "        # x_emb shape: (seq_len, batch_size, embed_size)\n",
    "        x_emb = self.drop(self.embed(inputs))\n",
    "        \n",
    "        # x_rnn shape: (seq_len, batch_size, hidden_size)\n",
    "        x_rnn, _ = self.rnn(x_emb)\n",
    "        x_rnn = self.drop(x_rnn)\n",
    "        \n",
    "        # outputs shape: (seq_len, batch_size, vocab_size)\n",
    "        return self.linear(x_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (embed): Embedding(50002, 300)\n",
       "  (rnn): LSTM(300, 500, num_layers=2, dropout=0.5)\n",
       "  (linear): Linear(in_features=500, out_features=50002, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(\n",
    "    rnn_type='LSTM', \n",
    "    n_token=len(text_field.vocab),\n",
    "    n_embed=300,\n",
    "    n_hidden=500,\n",
    "    n_layers=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3905f1095474910b1c76136413cb1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcdcd6480f7431382b4c1016422b204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=532.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7d2f2235fa4a4db69457dc293d6d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae882d5a530842dab49d43c832c34048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=532.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_epochs = 2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\n",
    "history = defaultdict(list)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm.notebook.tqdm(train_iter)\n",
    "    pbar.set_description(f'Epoch {epoch+1} --> Train')\n",
    "    \n",
    "    for i, batch in enumerate(pbar):\n",
    "        inputs, targets = batch.text.to(device), batch.target.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # outputs shape: (seq_len * batch_size, vocab_size)\n",
    "        outputs = outputs.view(-1, outputs.size(2))\n",
    "        # targets shape: (seq_len * batch_size)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    train_loss = total_loss / len(train_iter)\n",
    "    history['train_loss'].append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm.notebook.tqdm(valid_iter)\n",
    "    pbar.set_description(f'Epoch {epoch+1} --> Valid')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(pbar):\n",
    "            inputs, targets = batch.text.to(device), batch.target.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs = outputs.view(-1, outputs.size(2))\n",
    "            targets = targets.view(-1)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            \n",
    "    valid_loss = total_loss / len(valid_iter)\n",
    "    history['valid_loss'].append(valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity in Valid: 215.8343580612766\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity in Valid:', np.exp(history['valid_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
